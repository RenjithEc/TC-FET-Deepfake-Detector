{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing one video: F:/dataset/DeeperForensics-1.0/manipulated_videos/end_to_end_level_1\\711_M007.mp4...\n",
      "\n",
      "ðŸ“Š Video Processed: 711_M007.mp4\n",
      "   - ðŸŸ¢ Faces Extracted: 291\n",
      "   - ðŸ”µ Optical Flow Maps: 291\n",
      "   - ðŸ”´ Edge Maps: 291\n",
      "==================================================\n",
      "\n",
      "âœ… Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# Paths for input and output\n",
    "real_videos_dir = \"F:/dataset/DeeperForensics-1.0/source_videos\"\n",
    "fake_videos_dir = \"F:/dataset/DeeperForensics-1.0/manipulated_videos/end_to_end_level_1\"\n",
    "\n",
    "output_real_faces = \"E:/dataset_1/happy/real\"\n",
    "output_fake_faces = \"E:/dataset_1/happy/fake\"\n",
    "output_optical_flow = \"E:/dataset_1/happy/optical_flow\"\n",
    "output_edges = \"E:/dataset_1/happy/edges\"\n",
    "\n",
    "# Create directories if not exist\n",
    "for path in [output_real_faces, output_fake_faces, output_optical_flow, output_edges]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Load face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor_path = \"D:/school/Research/TC-FET-Deepfake-Detector/preprocessing/shape_predictor_68_face_landmarks.dat\"  \n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def compute_dense_optical_flow(prev_frame, next_frame):\n",
    "    \"\"\"Computes dense optical flow and converts it into an RGB representation.\"\"\"\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    \n",
    "    hsv = np.zeros_like(prev_frame)\n",
    "    hsv[..., 1] = 255\n",
    "    hsv[..., 0] = angle * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def extract_edges(frame):\n",
    "    \"\"\"Extracts edges from a frame using the Canny edge detection method.\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "def process_video(video_path, save_faces_dir, save_flow_dir, save_edges_dir):\n",
    "    \"\"\"Extracts faces and ensures optical flow and edge maps match the face frames.\"\"\"\n",
    "    folder_name = os.path.basename(os.path.dirname(video_path))  # Get folder name for naming\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "    frame_count = 0\n",
    "\n",
    "    # Counters for statistics\n",
    "    face_count = 0\n",
    "    flow_count = 0\n",
    "    edge_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        if faces:  # Only process optical flow and edges if a face is found\n",
    "            for i, face in enumerate(faces):\n",
    "                landmarks = predictor(gray, face)\n",
    "                interocular_distance = landmarks.part(42).x - landmarks.part(39).x\n",
    "\n",
    "                x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "                size = 5 * interocular_distance  # Increase bounding box size\n",
    "\n",
    "                x1 = max(0, x - size)\n",
    "                y1 = max(0, y - size)\n",
    "                x2 = min(frame.shape[1], x + size)\n",
    "                y2 = min(frame.shape[0], y + size)\n",
    "\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                if face_crop.shape[0] > 0 and face_crop.shape[1] > 0:  # Ensure valid cropping\n",
    "                    face_resized = cv2.resize(face_crop, (299, 299))\n",
    "\n",
    "                    filename_base = f\"{folder_name}_{os.path.basename(video_path)}_frame{frame_count}_face{i}\"\n",
    "                    filename_face = f\"{filename_base}.jpg\"\n",
    "                    filename_flow = f\"{filename_base}_flow.jpg\"\n",
    "                    filename_edges = f\"{filename_base}_edges.jpg\"\n",
    "\n",
    "                    # Save face\n",
    "                    cv2.imwrite(os.path.join(save_faces_dir, filename_face), face_resized)\n",
    "                    face_count += 1\n",
    "\n",
    "                    # Compute optical flow and crop to face region\n",
    "                    if prev_frame is not None:\n",
    "                        flow_map = compute_dense_optical_flow(prev_frame, frame)\n",
    "                        flow_crop = flow_map[y1:y2, x1:x2]\n",
    "                        if flow_crop.shape[0] > 0 and flow_crop.shape[1] > 0:\n",
    "                            flow_resized = cv2.resize(flow_crop, (299, 299))\n",
    "                            cv2.imwrite(os.path.join(save_flow_dir, filename_flow), flow_resized)\n",
    "                            flow_count += 1\n",
    "\n",
    "                    # Compute edges and crop to face region\n",
    "                    edge_map = extract_edges(frame)\n",
    "                    edge_crop = edge_map[y1:y2, x1:x2]\n",
    "                    if edge_crop.shape[0] > 0 and edge_crop.shape[1] > 0:\n",
    "                        edge_resized = cv2.resize(edge_crop, (299, 299))\n",
    "                        cv2.imwrite(os.path.join(save_edges_dir, filename_edges), edge_resized)\n",
    "                        edge_count += 1\n",
    "\n",
    "        prev_frame = frame\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Print statistics for this video\n",
    "    print(f\"\\nðŸ“Š Video Processed: {os.path.basename(video_path)}\")\n",
    "    print(f\"   - ðŸŸ¢ Faces Extracted: {face_count}\")\n",
    "    print(f\"   - ðŸ”µ Optical Flow Maps: {flow_count}\")\n",
    "    print(f\"   - ðŸ”´ Edge Maps: {edge_count}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def process_one_video(root_dir, save_faces_dir, save_flow_dir, save_edges_dir, check_happy=False):\n",
    "    \"\"\"Finds and processes only one video from the directory.\"\"\"\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        if check_happy and \"happy\" not in root.lower():\n",
    "            continue  # Skip this folder if 'happy' is not in its path\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp4\") or file.endswith(\".avi\"):\n",
    "                video_path = os.path.join(root, file)\n",
    "                print(f\"Processing one video: {video_path}...\")\n",
    "                process_video(video_path, save_faces_dir, save_flow_dir, save_edges_dir)\n",
    "                return  # Exit after processing the first video found\n",
    "\n",
    "# Process only ONE video from real videos (source_videos) that has 'happy' in its path\n",
    "process_one_video(real_videos_dir, output_real_faces, output_optical_flow, output_edges, check_happy=True)\n",
    "\n",
    "# Process only ONE video from fake videos (manipulated_videos) that has 'happy' in its path\n",
    "process_one_video(fake_videos_dir, output_fake_faces, output_optical_flow, output_edges, check_happy=False)\n",
    "\n",
    "print(\"\\nâœ… Processing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
